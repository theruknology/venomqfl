{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VENOM Quantum Backdoor Attack - Adaptive & Stealthy Implementation\n",
    "# Includes: Tunable Poison Ratio, Adaptive Quantum Injection, and FedAvg Defenses\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "# ========== Config ==========\n",
    "num_clients = 10\n",
    "malicious_client_fraction = 0.2  # 20% of selected clients are malicious\n",
    "poison_ratio = 0.2               # 20% of local data is poisoned\n",
    "target_label = 0                 # Target class for the backdoor\n",
    "trigger_interval = 5            # Inject VENOM every n rounds\n",
    "num_byzantine = int(num_clients * malicious_client_fraction)\n",
    "\n",
    "defense = 'trimmed_mean'        # Options: 'fedavg', 'trimmed_mean', 'krum'\n",
    "\n",
    "# ========== Dummy Model ==========\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x.view(x.size(0), -1))\n",
    "\n",
    "# ========== Poisoning Logic ==========\n",
    "def poison_data(data, labels, poison_ratio, target_label):\n",
    "    num_poison = int(len(data) * poison_ratio)\n",
    "    poisoned_data = data[:num_poison]\n",
    "    poisoned_labels = torch.full((num_poison,), target_label, dtype=torch.long)\n",
    "    clean_data = data[num_poison:]\n",
    "    clean_labels = labels[num_poison:]\n",
    "    return torch.cat([clean_data, poisoned_data]), torch.cat([clean_labels, poisoned_labels])\n",
    "\n",
    "# ========== VENOM Injection (Adaptive Quantum Resonance) ==========\n",
    "def generate_quantum_resonance_pattern(round_num):\n",
    "    # Simulates adaptive quantum perturbation (dummy implementation)\n",
    "    return torch.sin(torch.tensor(round_num * np.pi / 10))\n",
    "\n",
    "def inject_backdoor(model, quantum_seed):\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param.add_(quantum_seed * torch.randn_like(param) * 0.01)  # Adaptive, small perturbations\n",
    "\n",
    "# ========== Local Training ==========\n",
    "def local_train(model, data, labels, malicious=False, round_num=0):\n",
    "    model = deepcopy(model)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    if malicious:\n",
    "        data, labels = poison_data(data, labels, poison_ratio, target_label)\n",
    "        if round_num % trigger_interval == 0:\n",
    "            quantum_seed = generate_quantum_resonance_pattern(round_num)\n",
    "            inject_backdoor(model, quantum_seed)\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(1):  # Simulated local epoch\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model.state_dict()\n",
    "\n",
    "# ========== Aggregation Strategies ==========\n",
    "def average_models(models):\n",
    "    avg_model = deepcopy(models[0])\n",
    "    for key in avg_model:\n",
    "        for i in range(1, len(models)):\n",
    "            avg_model[key] += models[i][key]\n",
    "        avg_model[key] /= len(models)\n",
    "    return avg_model\n",
    "\n",
    "def trimmed_mean(updates, trim_ratio=0.1):\n",
    "    keys = updates[0].keys()\n",
    "    trimmed = {}\n",
    "    for key in keys:\n",
    "        stacked = torch.stack([update[key] for update in updates])\n",
    "        sorted_vals, _ = torch.sort(stacked, dim=0)\n",
    "        trim_n = int(len(updates) * trim_ratio)\n",
    "        trimmed[key] = torch.mean(sorted_vals[trim_n:-trim_n], dim=0)\n",
    "    return trimmed\n",
    "\n",
    "def krum(updates, num_byzantine):\n",
    "    distances = []\n",
    "    for i, update_i in enumerate(updates):\n",
    "        dists = [torch.norm(update_i[key] - update_j[key]) for j, update_j in enumerate(updates) if i != j for key in update_i]\n",
    "        dists = torch.tensor(dists).view(len(updates)-1, -1).sum(dim=1)\n",
    "        dists, _ = torch.sort(dists)\n",
    "        distances.append((i, torch.sum(dists[:len(updates) - num_byzantine - 2])))\n",
    "    chosen_index = min(distances, key=lambda x: x[1])[0]\n",
    "    return updates[chosen_index]\n",
    "\n",
    "def aggregate(updates):\n",
    "    if defense == 'fedavg':\n",
    "        return average_models(updates)\n",
    "    elif defense == 'trimmed_mean':\n",
    "        return trimmed_mean(updates)\n",
    "    elif defense == 'krum':\n",
    "        return krum(updates, num_byzantine)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid defense strategy\")\n",
    "\n",
    "# ========== Federated Loop ==========\n",
    "def federated_learning(rounds, dataset):\n",
    "    global_model = SimpleNN()\n",
    "\n",
    "    for r in range(rounds):\n",
    "        selected_clients = random.sample(range(num_clients), num_clients)\n",
    "        num_malicious = int(malicious_client_fraction * num_clients)\n",
    "        malicious_clients = set(random.sample(selected_clients, num_malicious))\n",
    "\n",
    "        local_updates = []\n",
    "\n",
    "        for i in selected_clients:\n",
    "            # Simulated local data and labels\n",
    "            data = torch.randn(32, 1, 28, 28)  # fake batch of MNIST\n",
    "            labels = torch.randint(0, 10, (32,))\n",
    "            is_malicious = i in malicious_clients\n",
    "\n",
    "            update = local_train(global_model, data, labels, malicious=is_malicious, round_num=r)\n",
    "            local_updates.append(update)\n",
    "\n",
    "        aggregated_update = aggregate(local_updates)\n",
    "        global_model.load_state_dict(aggregated_update)\n",
    "\n",
    "        print(f\"Round {r+1} completed\")\n",
    "\n",
    "    return global_model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
